{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buisness Understanding\n",
    "**Stakeholder:** \n",
    "* Medical Device Company\n",
    "\n",
    "**Problem:** \n",
    "* The major issue is being unable to produce effective monitoring and treatment technologies for myocardial infarction (MI) survivors. Being able to predict myocardial complications is essential for advancing technologies in this background. MI can occur without complications or with complications that do not worsen the long-term prognosis. However about half of the patients in the acute and subacute periods have complications that lead to worsening of the disease and even death. Predicting complications of myocardial infarction is importnat in order to carry out the necessary preventive measures in upcoming developing medical devices that will keep those complication in mind.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding\n",
    "\n",
    "**Source:**\n",
    "* [University of California Irvine (UCI) Machine Learning Repositories](https://archive.ics.uci.edu/) \n",
    "\n",
    "**Dataset:**\n",
    "* [Myocardial Infarction Complications](https://archive.ics.uci.edu/dataset/579/myocardial+infarction+complications)\n",
    "    * 1700 rows, 124 columns \n",
    "    * 8 potential Target columns, 116 Feature columns\n",
    "    * All the column names and defintions can be found in the [Column Descriptions](../data/column_descriptions.md) file\n",
    "\n",
    "**Targets (Myocardial Infarction Complications):**\n",
    "* FIBR_PREDS (Atrial Fibrillation) \n",
    "    * Life-threatening, irregular heartbeat caused by fast and irregular contractions in the upper chambers of the heart. Prevents the heart from pumping blood to the lower chamber of the heart\n",
    "* PREDS_TAH (Supraventricular Tachycardia)\n",
    "    * Irregular, fast, or erratic heartbeat that affects the heart's upper chambers. Its not usually serious and does not cause sudden death, heart damage, or heart attacks. In extreme cases that can result but its very unlikely.\n",
    "* JELUD_TAH (Ventricular Tachycardia)\n",
    "    * Irregular, fast, or erratic heartbeat that affects the heart's lower chambers. Can become life-threatening if the episode lasts longer than a few seconds also known as a sustained Ventricular Tachycardia. \n",
    "* FIBR_JELUD (Ventricular Fibrillation)\n",
    "    * Life-threatening, irregular heartbeat that affects the heart's ventricles. The lower heart chambers contract rapidly and in an uncoordinated manner. As a result, prevents the heart from pumping blood to the rest of the body.\n",
    "* A_V_BLOK (Third-degree AV block)\n",
    "    * Medical condition that occurs when there is a complete loss of communcation between the heart's atria and ventricles. In other words, electrical signals cannot pass from the atria to the ventricles.   \n",
    "* OTEK_LANC (Pulmonary edema)\n",
    "    * Life-threatening condition caused by fluid build up in the lungs. This fluid collects in the air sacs in the lungs, making it difficult to breathe.\n",
    "* RAZRIV (Myocardial rupture)\n",
    "    * Tear in the heart that occurs after a heart attack. Is life-threatening however is a rare complication of a heart attack.\n",
    "* DRESSLER (Dressler Syndrome)\n",
    "    * Inflammation of the sac (pericardium) surrounding the heart. Immune system response due to damage to heart tissue or the sac itself.\n",
    "\n",
    "**Data Types:**\n",
    "\n",
    "For this dataset almost all columns have already been numerically encoded for nominal and ordinal columns. There are columns that are numeric that represent realtime values that were taken. These need to be scaled so they don't dramatically impact the modeling results.\n",
    "\n",
    "Kept Continous Data: \n",
    "* ALT_BLOOD (Serum AIAT content)\n",
    "* AST_BLOOD (Serum AsAT Content)\n",
    "* L_BLOOD (White Blood Cell Count)\n",
    "* AGE (Age of patient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets split data into a train-test split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../data/data_cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>INF_ANAM</th>\n",
       "      <th>STENOK_AN</th>\n",
       "      <th>FK_STENOK</th>\n",
       "      <th>IBS_POST</th>\n",
       "      <th>GB</th>\n",
       "      <th>SIM_GIPERT</th>\n",
       "      <th>DLIT_AG</th>\n",
       "      <th>...</th>\n",
       "      <th>PREDS_TAH</th>\n",
       "      <th>JELUD_TAH</th>\n",
       "      <th>FIBR_JELUD</th>\n",
       "      <th>A_V_BLOK</th>\n",
       "      <th>OTEK_LANCRAZRIV</th>\n",
       "      <th>DRESSLER</th>\n",
       "      <th>ZSN</th>\n",
       "      <th>REC_IM</th>\n",
       "      <th>P_IM_STEN</th>\n",
       "      <th>LET_IS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  AGE  SEX  INF_ANAM  STENOK_AN  FK_STENOK  IBS_POST  GB  SIM_GIPERT  \\\n",
       "0   2   55    1         1        0.0        0.0         0   0           0   \n",
       "1   6   64    1         0        1.0        2.0         1   0           0   \n",
       "2   7   70    1         1        1.0        2.0         1   2           0   \n",
       "3  10   77    0         2        0.0        0.0         0   3           0   \n",
       "4  11   71    1         0        0.0        0.0         0   0           0   \n",
       "\n",
       "   DLIT_AG  ...  PREDS_TAH  JELUD_TAH  FIBR_JELUD  A_V_BLOK  OTEK_LANCRAZRIV  \\\n",
       "0      0.0  ...          0          0           0         0                0   \n",
       "1      0.0  ...          0          0           0         0                0   \n",
       "2      7.0  ...          0          0           0         0                0   \n",
       "3      6.0  ...          0          0           0         0                0   \n",
       "4      0.0  ...          0          0           0         0                0   \n",
       "\n",
       "   DRESSLER  ZSN  REC_IM  P_IM_STEN  LET_IS  \n",
       "0         0    0       0          0       0  \n",
       "1         0    0       0          0       0  \n",
       "2         0    0       1          0       0  \n",
       "3         0    0       1          0       0  \n",
       "4         0    0       0          0       0  \n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define X, y \n",
    "X = df.iloc[:, :-12] # Features\n",
    "y = df.iloc[:, -12:] # Targets\n",
    "\n",
    "# Perform split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets standardize our contnous columns in our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our numeric columns that need to be normalized\n",
    "numeric_features = [\n",
    "    \"ALT_BLOOD\",\n",
    "    \"AST_BLOOD\",\n",
    "    \"L_BLOOD\",\n",
    "    \"AGE\"\n",
    "]\n",
    "\n",
    "X_train_numeric = X_train[numeric_features].copy()\n",
    "X_test_numeric = X_test[numeric_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Instantiate scaler \n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit Scaler to continous training data\n",
    "scaler.fit(X_train_numeric)\n",
    "\n",
    "# Concatenate training data and testing data respectively\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_train_numeric), \n",
    "    index=X_train_numeric.index,\n",
    "    columns=X_train_numeric.columns\n",
    ")\n",
    "\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test_numeric), \n",
    "    index=X_test_numeric.index,\n",
    "    columns=X_test_numeric.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\delga\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\frame.py:4163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the scaled data with the original training data and drop the columns that are not scaled\n",
    "\n",
    "# Drop old columns\n",
    "X_train.drop(columns=numeric_features, inplace=True)\n",
    "X_test.drop(columns=numeric_features, inplace=True)\n",
    "\n",
    "# Concatenate the scaled data with the original training data \n",
    "X_train_full = pd.concat([X_train, X_train_scaled], axis=1)\n",
    "X_test_full = pd.concat([X_test, X_test_scaled], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create baseline moedels with no modifications to there performances. The well known fact about this dataset is that there are class imbalances so the baseline moedels should perform poorly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Pipeline(steps=[('classifier',\n",
      "                 MultiOutputClassifier(estimator=LogisticRegression(C=1000000000000.0,\n",
      "                                                                    fit_intercept=False,\n",
      "                                                                    solver='liblinear')))])...\n",
      "Evaluating Pipeline(steps=[('classifier',\n",
      "                 MultiOutputClassifier(estimator=LogisticRegression(C=1000000000000.0,\n",
      "                                                                    fit_intercept=False,\n",
      "                                                                    solver='liblinear')))])...\n",
      "Log Loss:13.610393938159273\n",
      "\n",
      "========================================\n",
      "\n",
      "Pipeline(steps=[('classifier',\n",
      "                 MultiOutputClassifier(estimator=LogisticRegression(C=1000000000000.0,\n",
      "                                                                    fit_intercept=False,\n",
      "                                                                    solver='liblinear')))]) Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      TRENT_S_n       0.41      0.21      0.28        72\n",
      "     FIBR_PREDS       0.19      0.08      0.12        36\n",
      "      PREDS_TAH       0.00      0.00      0.00         6\n",
      "      JELUD_TAH       0.00      0.00      0.00        10\n",
      "     FIBR_JELUD       0.00      0.00      0.00        13\n",
      "       A_V_BLOK       0.00      0.00      0.00         8\n",
      "OTEK_LANCRAZRIV       0.40      0.22      0.29        27\n",
      "       DRESSLER       0.33      0.15      0.21        13\n",
      "            ZSN       0.12      0.11      0.12         9\n",
      "         REC_IM       0.50      0.19      0.28        73\n",
      "      P_IM_STEN       0.00      0.00      0.00        33\n",
      "         LET_IS       0.20      0.04      0.07        23\n",
      "\n",
      "      micro avg       0.29      0.13      0.18       323\n",
      "      macro avg       0.18      0.08      0.11       323\n",
      "   weighted avg       0.29      0.13      0.18       323\n",
      "    samples avg       0.10      0.09      0.09       323\n",
      "\n",
      "\n",
      "========================================\n",
      "\n",
      "Training Pipeline(steps=[('classifier',\n",
      "                 MultiOutputClassifier(estimator=RandomForestClassifier()))])...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\delga\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\delga\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Pipeline(steps=[('classifier',\n",
      "                 MultiOutputClassifier(estimator=RandomForestClassifier()))])...\n",
      "Log Loss:4.213533347034935\n",
      "\n",
      "========================================\n",
      "\n",
      "Pipeline(steps=[('classifier',\n",
      "                 MultiOutputClassifier(estimator=RandomForestClassifier()))]) Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      TRENT_S_n       0.33      0.04      0.07        72\n",
      "     FIBR_PREDS       1.00      0.03      0.05        36\n",
      "      PREDS_TAH       0.00      0.00      0.00         6\n",
      "      JELUD_TAH       0.00      0.00      0.00        10\n",
      "     FIBR_JELUD       0.00      0.00      0.00        13\n",
      "       A_V_BLOK       0.00      0.00      0.00         8\n",
      "OTEK_LANCRAZRIV       0.00      0.00      0.00        27\n",
      "       DRESSLER       0.00      0.00      0.00        13\n",
      "            ZSN       0.00      0.00      0.00         9\n",
      "         REC_IM       0.94      0.21      0.34        73\n",
      "      P_IM_STEN       0.00      0.00      0.00        33\n",
      "         LET_IS       0.00      0.00      0.00        23\n",
      "\n",
      "      micro avg       0.73      0.06      0.11       323\n",
      "      macro avg       0.19      0.02      0.04       323\n",
      "   weighted avg       0.40      0.06      0.10       323\n",
      "    samples avg       0.06      0.05      0.05       323\n",
      "\n",
      "\n",
      "========================================\n",
      "\n",
      "Training Pipeline(steps=[('classifier',\n",
      "                 MultiOutputClassifier(estimator=KNeighborsClassifier()))])...\n",
      "Evaluating Pipeline(steps=[('classifier',\n",
      "                 MultiOutputClassifier(estimator=KNeighborsClassifier()))])...\n",
      "Log Loss:11.225822004807405\n",
      "\n",
      "========================================\n",
      "\n",
      "Pipeline(steps=[('classifier',\n",
      "                 MultiOutputClassifier(estimator=KNeighborsClassifier()))]) Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      TRENT_S_n       0.39      0.22      0.28        72\n",
      "     FIBR_PREDS       0.92      0.31      0.46        36\n",
      "      PREDS_TAH       0.00      0.00      0.00         6\n",
      "      JELUD_TAH       0.00      0.00      0.00        10\n",
      "     FIBR_JELUD       0.50      0.08      0.13        13\n",
      "       A_V_BLOK       0.00      0.00      0.00         8\n",
      "OTEK_LANCRAZRIV       0.67      0.22      0.33        27\n",
      "       DRESSLER       0.62      0.38      0.48        13\n",
      "            ZSN       0.17      0.11      0.13         9\n",
      "         REC_IM       0.15      0.05      0.08        73\n",
      "      P_IM_STEN       0.80      0.24      0.37        33\n",
      "         LET_IS       0.85      0.48      0.61        23\n",
      "\n",
      "      micro avg       0.50      0.20      0.28       323\n",
      "      macro avg       0.42      0.17      0.24       323\n",
      "   weighted avg       0.47      0.20      0.27       323\n",
      "    samples avg       0.20      0.14      0.16       323\n",
      "\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\delga\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\delga\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\delga\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\delga\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\delga\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\delga\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Create Pipeline \n",
    "# Define the pipelines for each algorithm Baseline\n",
    "logreg_pipeline = Pipeline([\n",
    "    ('classifier', MultiOutputClassifier(LogisticRegression(fit_intercept=False, C=1e12, solver='liblinear')))\n",
    "])\n",
    "\n",
    "rf_pipeline = Pipeline([\n",
    "    ('classifier', MultiOutputClassifier(RandomForestClassifier()))\n",
    "])\n",
    "\n",
    "knn_pipeline = Pipeline([\n",
    "    ('classifier', MultiOutputClassifier(KNeighborsClassifier()))\n",
    "])\n",
    "\n",
    "# Fit and evaluate the each baseline pipeline\n",
    "pipelines = [logreg_pipeline, rf_pipeline, knn_pipeline]\n",
    "\n",
    "# Fit and evaluate each pipeline\n",
    "for i, pipeline in enumerate([logreg_pipeline, rf_pipeline, knn_pipeline]):\n",
    "    print(f\"Training {pipelines[i]}...\")\n",
    "    \n",
    "    # Fit the pipeline on the training data\n",
    "    pipeline.fit(X_train_full, y_train)\n",
    "\n",
    "    print(f\"Evaluating {pipelines[i]}...\")\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    predictions = pipeline.predict(X_test_full)\n",
    "\n",
    "    # Evaluate the pipeline's performance\n",
    "    loss = log_loss(y_test, predictions)\n",
    "    report = classification_report(y_test, predictions, target_names=y.columns)\n",
    "\n",
    "    print(f\"Log Loss:{loss}\")\n",
    "    print(\"\\n\" + \"=\" * 40 + \"\\n\")\n",
    "    print(f\"{pipelines[i]} Classification Report:\\n\", report)\n",
    "    print(\"\\n\" + \"=\" * 40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected we did poorly. In every model we have very low recall (Sensitivity). This suggests our models can't predict actual positive cases. The log loss for all models are very high. \n",
    "\n",
    "The next step is to fix the class imbalance in our data because this is significantly influencing prediction capabilities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Imbalance\n",
    "\n",
    "We cant oversample because some feature are just so rare that it can be 1 or 2. Undersampling is a possibility however it runs the risk of underfitting. \n",
    "\n",
    "We can use Synthetic Minority Oversampling (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
